{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7dd515d",
   "metadata": {},
   "source": [
    "# ERROR:\n",
    "File size limits killing kernel. Function to export list of matrices breaks after first round of pickling. Managed to brute force my way through a chunk of data, but the two resulting .pkl files are 14GB and 18GB, which is a. too large considering this is only a quarter of the data, and b. doesn't make sense (first should be larger than second, so they might also be bust). But can't tell bc pickle can't handle importing something that large...  \n",
    "  \n",
    "EDIT: Kernel survives by editing function so pickling occurs at len=2000 instead of 3000, and using smaller dimensions for matrices (lower resolution). Now 3x12 GBs of pickled lists, doubtful this is the best way to go about data management.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8cfbc2",
   "metadata": {},
   "source": [
    "# Generating model inputs from raw audio\n",
    "\n",
    "Generating spectrograms and then saving those images as _images_ loses much of the information stored in the spectrogram input data. The spectrogram input is a complex-valued matrix D, consisting of magnitude and phase of frequency bin f at frame t. A plotted spectrogram shows time on the x-axis, frequency on the y-axis, with amplitude/intensity/decibels as color.  The data here have a minimum sample rate of 50KHz, signifying 50,000 samples per second for the :30 clip. The frequency and time binning done to generate spectrogram matrices groups these 1.5M+ 'samples' into windows of specified length; the lowest resolution used for marine mammal acoustics yields a matrix of dimensions >1000 x >1000.\n",
    "\n",
    "If transposing the resulting image to a .png and reimporting, the resulting matrix dimensions represent pixels (based on physical size of export), and resulting matrix values represent a color on a different scale than audio intensity. Very nuanced standardization of spectrograms, cmaps, etc may yield a comparable input for CNN; but given the significant smoothing, binning, resampling, frequency ranges, and other parameters that go into generating each spectrogram matrix, I think the information loss is too great, or at least too unquantifiable.\n",
    "\n",
    "To \"feed spectrograms to CNN\", what we want is the true spectrogram matrix, not the matrix of the .png (or other image format) rendering of the spectrogram matrix. \n",
    "\n",
    "---\n",
    "Parameters used herein, based on marine mammal and underwater acoustic literature review:\n",
    "* sr=50KHz --> all data are either 50k or 64k; resample the 64k files to 50k so working with equal times per frame\n",
    "* n_fft=4096; downsized to accommodate file size issues. Ideal was n_fft>=8192 (based on methods from Thomas et al 2019, and applying to the unique attributes of _S. longirostris_ vocalizations)\n",
    "    * n_fft=128 could best capture clicks (bursts and/or trains) \n",
    "        * 128/50000 = .00256 sec = 2560$\\mu$s per FFT\n",
    "        * fastest dolphin clicks (burst pulses) ~ 1750 clicks/sec = 570$\\mu$s between clicks, each click 50-128 $\\mu$s duration \n",
    "        * 2560$\\mu$s window could capture several clicks; too short for whistles\n",
    "    * more inclusive window ~ sr/4 = 12500 --> n_fft=8192(.16 sec); n_fft=16384(.33s)\n",
    "        * _S. longirostris_ whistle duration = 0.05-1.28s, avg .49s\n",
    "        * don't want to exceed n_fft=16384 (next power of 2 > 32K) because matrix size getting out of hand\n",
    "    * Future goal: use multiple n_fft windows: train separate NNs on spectrograms of different n_ffts and compare performance, OR stack/interpolate into single spectrogram \n",
    "* win_length = n_fft\n",
    "    * Future: smaller values to better discriminate clicks\n",
    "* hop_length = n_fft/2; downsized to accommodate file size issues. Ideal was win_length/4 (default)\n",
    "* window: Hann window\n",
    "    * forces signal in a block to be periodic\n",
    "    * Future: Hamming, Blackman\n",
    "    \n",
    "---\n",
    "  \n",
    "This notebook generates spectrogram matrices for training and test data with Librosa's stft function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b374f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T07:00:34.466706Z",
     "start_time": "2021-06-01T07:00:30.614750Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import wave\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf38e82",
   "metadata": {},
   "source": [
    "## Step 1. set aside holdout set\n",
    "This set will remain separate from regular train/test data for final validation.  \n",
    "500 positive files, 1538 negative files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "707be980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T05:40:33.930110Z",
     "start_time": "2021-06-01T05:40:33.924860Z"
    }
   },
   "outputs": [],
   "source": [
    "#relocate positives and negatives from existing folders to holdout folders\n",
    "def define_holdout(n_pos, pos_origin, pos_dest, n_neg, neg_origin, neg_dest):\n",
    "    import shutil\n",
    "    \n",
    "    #positives\n",
    "    for i in range(n_pos):\n",
    "        shutil.move(pos_origin + np.random.choice(os.listdir(pos_origin)), pos_dest)\n",
    "        \n",
    "    #negatives\n",
    "    for j in range(n_neg):\n",
    "        shutil.move(neg_origin + np.random.choice(os.listdir(neg_origin)), neg_dest)\n",
    "        \n",
    "    print(f'# positives in holdout: {len(os.listdir(pos_dest))}')\n",
    "    print(f'# negatives in holdout: {len(os.listdir(neg_dest))}')\n",
    "    print(f'# pos for tts: {len(os.listdir(pos_origin))}')\n",
    "    print(f'# neg for tts: {len(os.listdir(neg_origin))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d16a3d2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T05:40:34.999066Z",
     "start_time": "2021-06-01T05:40:34.995853Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_origin = '../scratch_data/yes_dolphin/'\n",
    "pos_dest = '../scratch_data/holdout/positives'\n",
    "neg_origin = '../scratch_data/no_dolphin/'\n",
    "neg_dest = '../scratch_data/holdout/negatives'\n",
    "\n",
    "# define_holdout(500, pos_origin, pos_dest, 1538, neg_origin, neg_dest)\n",
    "\n",
    "# positives in holdout: 501\n",
    "# negatives in holdout: 1538\n",
    "# pos for tts: 5588\n",
    "# neg for tts: 16766"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d76f42c",
   "metadata": {},
   "source": [
    "## Step 2. Create spectrograms for tts\n",
    "* Pos and Neg files currently only differentiated by directory; attach label (Yes/No) here\n",
    "* Save spectrogram matrices and labels in list(s), save list via pickle or librosa cache?\n",
    "\n",
    "---\n",
    "* Adding all pos ID spectrogram matrices (only 1/4 total tts data) to a single list breaks kernel somewhere between 4000-5000 files. Instead, pickle increments of 2000, tupled with their presence/absence labels.\n",
    "* Kernel still died after exporting first pkl @ 3000 (presumably emptying spectrolist, so _list_ size not the issue now; must be pickle limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3a66790",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T07:04:45.837407Z",
     "start_time": "2021-06-01T07:04:45.829490Z"
    }
   },
   "outputs": [],
   "source": [
    "def listospects(in_path, n_fft, win_length, window, pos_neg, ex_path):\n",
    "    import pickle\n",
    "    \n",
    "    files = os.listdir(in_path)\n",
    "    spectrolist = []\n",
    "    count = 1\n",
    "    \n",
    "    for i in files:\n",
    "    #for i in range(3001, len(files)):  #for when you had to rerun from the middle...\n",
    "        y, sr = librosa.load(in_path + i, sr=50000) #hardcode sr\n",
    "        S = np.abs(librosa.stft(y, n_fft=n_fft, win_length=win_length, hop_length=int(n_fft/2),\n",
    "                               window=window))\n",
    "        \n",
    "        spectrolist.append((S, pos_neg)) #append tuple: ([spectro matrix], presence/absence)\n",
    "        \n",
    "        if len(spectrolist) % 1000 == 0:\n",
    "            print(len(spectrolist))\n",
    "            \n",
    "        if len(spectrolist) % 2000 == 0: #save results so far and clear list (size limits?)\n",
    "            with open(f'{ex_path}tts_{count}.pkl', mode = 'wb') as pickle_out:\n",
    "                pickle.dump(spectrolist, pickle_out)\n",
    "            count += 1\n",
    "            spectrolist = []\n",
    "    #export whatever's in list when pau        \n",
    "    if len(spectrolist) > 0:\n",
    "        with open(f'{ex_path}tts_{count}.pkl', mode = 'wb') as pickle_out:\n",
    "            pickle.dump(spectrolist, pickle_out)\n",
    "            \n",
    "    print(\"thanks for all the fish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8868fc1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-01T04:13:57.291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "#positive IDs first\n",
    "#kernel dies after first pickle_out\n",
    "\n",
    "in_path = '../scratch_data/yes_dolphin/'\n",
    "ex_path = '../scratch_data/tts_matrices/'\n",
    "# yes_tts = listospects(in_path=in_path, n_fft=8192, win_length=8192,\n",
    "#                       window=signal.windows.hann, pos_neg=1, ex_path=ex_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d36548",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T03:54:03.055956Z",
     "start_time": "2021-06-01T03:53:54.926710Z"
    }
   },
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fb46aec66fcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'../scratch_data/tts_matrices/tts_1a.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpickle_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mworkplease\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open ('../scratch_data/tts_matrices/tts_1a.pkl', mode = 'rb') as pickle_in:\n",
    "    workplease = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8861288",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T05:42:36.570000Z",
     "start_time": "2021-06-01T05:42:36.566031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14532512366"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize('../scratch_data/tts_matrices/tts_1a.pkl') #ruh roh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "358e5d4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T08:20:31.127182Z",
     "start_time": "2021-06-01T07:07:09.426002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "1000\n",
      "2000\n",
      "1000\n",
      "thanks for all the fish\n"
     ]
    }
   ],
   "source": [
    "# try with smaller n_fft?\n",
    "# changed hop_length to n_fft/2 in function for this example; chang back to ideal nfft/4 if can!\n",
    "in_path = '../scratch_data/yes_dolphin/'\n",
    "ex_path = '../scratch_data/tts_matrices/'\n",
    "fft_sm = 4096\n",
    "yes_tts = listospects(in_path=in_path, n_fft=fft_sm, win_length=fft_sm,\n",
    "                      window=signal.windows.hann, pos_neg=1, ex_path=ex_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e802b5e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T08:26:47.343565Z",
     "start_time": "2021-06-01T08:26:41.643061Z"
    }
   },
   "outputs": [],
   "source": [
    "with open ('../scratch_data/tts_matrices/tts_1.pkl', mode = 'rb') as pickle_in:\n",
    "    howboutnow = pickle.load(pickle_in) #!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72c27760",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T08:27:20.574574Z",
     "start_time": "2021-06-01T08:27:20.568600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2049, 740)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "howboutnow[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d188044",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T08:28:11.295846Z",
     "start_time": "2021-06-01T08:28:11.290988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18104"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(howboutnow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad888b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f90cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bd4ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a736b7b",
   "metadata": {},
   "source": [
    "#### Random investigating matrix and file sizes\n",
    "The above function ended up working with the reduced matrix sizes. Not the resolution I was going for but could suffice if need. 33.9GB for just the positive files, roughly 1/4 total train-test-split data. This strikes me as somewhat bonkers considering the audio files themselves are 19.7GB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce4f11b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T07:01:18.774664Z",
     "start_time": "2021-06-01T07:01:18.772276Z"
    }
   },
   "outputs": [],
   "source": [
    "test_path = '../scratch_data/testinggg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb72160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T07:01:19.247372Z",
     "start_time": "2021-06-01T07:01:19.241458Z"
    }
   },
   "outputs": [],
   "source": [
    "test_files = os.listdir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb83ce3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T07:01:19.569204Z",
     "start_time": "2021-06-01T07:01:19.559489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['makua2016_00014626.e.wav',\n",
       " 'makua2016_00014642.e.wav',\n",
       " 'makua2016_00014611.e.wav',\n",
       " 'makua2016_00014628.e.wav',\n",
       " 'honolua2016_00000104.e.wav']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ca8ec6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T07:01:21.626335Z",
     "start_time": "2021-06-01T07:01:21.553157Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fft = 8192\n",
    "# win_length = n_fft (default)\n",
    "# hop_length = n_fft/4 (default)\n",
    "window = signal.windows.hann\n",
    "\n",
    "y, sr = librosa.load(test_path+test_files[0], sr=50000)\n",
    "S = np.abs(librosa.stft(y, n_fft=n_fft, win_length=n_fft, hop_length=int(n_fft/4), \n",
    "                        window=window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "511d1110",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T07:01:22.591719Z",
     "start_time": "2021-06-01T07:01:22.586296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4097, 739)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1791119",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T07:01:26.883302Z",
     "start_time": "2021-06-01T07:01:26.879361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12110852"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(S) #12_110_852 bytes = 12.11 MB * 5588 pos files = 67.67 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3914f574",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T07:01:27.983570Z",
     "start_time": "2021-06-01T07:01:27.978986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectlist = []\n",
    "spectlist.append((S,0))\n",
    "sys.getsizeof(spectlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b5162cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T07:01:51.095560Z",
     "start_time": "2021-06-01T07:01:51.054493Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fft_sm=4096\n",
    "y, sr = librosa.load(test_path+test_files[0], sr=50000)\n",
    "S_smaller = np.abs(librosa.stft(y, n_fft=n_fft_sm, hop_length=int(n_fft_sm/2), \n",
    "                        window=window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cee73a92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T07:01:52.152606Z",
     "start_time": "2021-06-01T07:01:52.148186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2049, 739)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_smaller.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0628de1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T05:51:10.403787Z",
     "start_time": "2021-06-01T05:51:10.400217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6056964\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "spectlist_sm=[]\n",
    "spectlist_sm.append((S_smaller,1))\n",
    "print(sys.getsizeof(S_smaller))\n",
    "print(sys.getsizeof(spectlist_sm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e1cae59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T05:53:35.589496Z",
     "start_time": "2021-06-01T05:53:33.916516Z"
    }
   },
   "outputs": [],
   "source": [
    "s_list=[]\n",
    "for i in test_files:\n",
    "    y, sr = librosa.load(test_path+i, sr=50000)\n",
    "    S = np.abs(librosa.stft(y, n_fft=n_fft, win_length=n_fft, hop_length=int(n_fft/4), \n",
    "                            window=window))\n",
    "    s_list.append((S,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cecf4611",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T05:54:19.399933Z",
     "start_time": "2021-06-01T05:54:19.396547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "120\n",
      "12110852\n"
     ]
    }
   ],
   "source": [
    "print(len(s_list))\n",
    "print(sys.getsizeof(s_list)) #so what's the deal?\n",
    "print(sys.getsizeof(s_list[0][0])) #oh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4369dfb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T05:58:59.109775Z",
     "start_time": "2021-06-01T05:58:59.058664Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../scratch_data/size_test.pkl', mode = 'wb') as pickle_out:\n",
    "    pickle.dump(s_list, pickle_out)\n",
    "\n",
    "    \n",
    "#60.6 MB in Finder, len=5. Projected len=5588 --> 338.5 GB woof\n",
    "with open('../scratch_data/size_test.pkl', mode = 'rb') as pickle_in:\n",
    "    size_check = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f2a0c8c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:02:20.754579Z",
     "start_time": "2021-06-01T06:02:20.750601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(size_check[0][0]) #120 bytes?  Why size difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4b8fc31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:03:35.056462Z",
     "start_time": "2021-06-01T06:03:35.051199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12110852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.15962058, 0.19476938, 0.18493547, ..., 0.7757199 , 0.7546011 ,\n",
       "         0.7965746 ],\n",
       "        [0.04913787, 0.1263316 , 0.11499742, ..., 0.4314431 , 0.33885133,\n",
       "         0.42975217],\n",
       "        [0.09760977, 0.0261576 , 0.05600911, ..., 0.15420917, 0.02857238,\n",
       "         0.11313909],\n",
       "        ...,\n",
       "        [0.0329048 , 0.07270378, 0.12733585, ..., 0.08322319, 0.13698879,\n",
       "         0.11471724],\n",
       "        [0.03562226, 0.01525263, 0.18407874, ..., 0.02256095, 0.11547531,\n",
       "         0.11492181],\n",
       "        [0.04500581, 0.0670425 , 0.21629652, ..., 0.0559493 , 0.1409184 ,\n",
       "         0.22505325]], dtype=float32),\n",
       " 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sys.getsizeof(s_list[0][0]))\n",
    "s_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8b74f35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:03:58.755509Z",
     "start_time": "2021-06-01T06:03:58.750194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.15962058, 0.19476938, 0.18493547, ..., 0.7757199 , 0.7546011 ,\n",
       "         0.7965746 ],\n",
       "        [0.04913787, 0.1263316 , 0.11499742, ..., 0.4314431 , 0.33885133,\n",
       "         0.42975217],\n",
       "        [0.09760977, 0.0261576 , 0.05600911, ..., 0.15420917, 0.02857238,\n",
       "         0.11313909],\n",
       "        ...,\n",
       "        [0.0329048 , 0.07270378, 0.12733585, ..., 0.08322319, 0.13698879,\n",
       "         0.11471724],\n",
       "        [0.03562226, 0.01525263, 0.18407874, ..., 0.02256095, 0.11547531,\n",
       "         0.11492181],\n",
       "        [0.04500581, 0.0670425 , 0.21629652, ..., 0.0559493 , 0.1409184 ,\n",
       "         0.22505325]], dtype=float32),\n",
       " 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sys.getsizeof(size_check[0][0])) #pickled version of s_list but order of magnitude diff\n",
    "size_check[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73772a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
