{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5cbb8786",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T05:25:03.208065Z",
     "start_time": "2021-05-29T05:25:03.205243Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb0c8c",
   "metadata": {},
   "source": [
    "# In this notebook:\n",
    "## 1. Create master list of all positive ID files\n",
    "* concatenate individual dataset logs  \n",
    "* bring in sample_rates.csv (varies by site) and attach to master list\n",
    "    \n",
    "\n",
    "## 2. Create loop to download data\n",
    "Transfer select files from external hardrive to local.\n",
    "* all positive ID files\n",
    "* random sample of negative files \n",
    "* they are all separated by site and have repeat filenames it's chaos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650b2935",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T23:11:20.587054Z",
     "start_time": "2021-05-28T23:11:20.582356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MM17b_20160630_20160830_triton output_MM.csv',\n",
       " 'Kahekili1_20160115_20160316_triton output_MM.csv',\n",
       " 'Kahekili2_20160630_20160830_triton output_MM.csv',\n",
       " 'MM17a_20160115_20160316_triton output_MM.csv',\n",
       " 'Lopa_20160930_20161130_triton output_MM.csv',\n",
       " 'Honolua_20161005_20161130_triton output_MM.csv',\n",
       " 'MauiLanai_20160630_20160830_triton output_MM.csv',\n",
       " 'Launiupoko_20160630_20160820_triton output_MM.csv',\n",
       " 'Makua_20161001_20161130_triton output_MM.csv',\n",
       " 'Manele_20160930_20161130_triton output_MM.csv',\n",
       " 'NorthMala_20160630_20160830_triton output_MM.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../scratch_data/positive_file_logs/'\n",
    "logs = [i for i in os.listdir(path) if '.csv' in i]\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd461ba1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T23:11:20.590084Z",
     "start_time": "2021-05-28T23:11:20.588323Z"
    }
   },
   "outputs": [],
   "source": [
    "def mass_import(path, listdir):\n",
    "    all_data = []\n",
    "    for i in listdir:\n",
    "        all_data.append(pd.read_csv(path+i))\n",
    "    return pd.concat(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "203fe6b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T23:11:20.701417Z",
     "start_time": "2021-05-28T23:11:20.591119Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/helenmeigs/miniforge3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3361: DtypeWarning: Columns (0,1,2,3,4,5,6,7,9,16,17,18) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "all_positives = mass_import(path, logs)\n",
    "all_positives.columns = all_positives.columns.str.lower().str.replace(' ','_')\n",
    "\n",
    "#all_positives.isnull().sum()  #64000 nulls from empty csv rows at the end of one df\n",
    "#drop nulls that are completely empty across all fields\n",
    "all_positives.dropna(how = 'all', inplace=True)\n",
    "\n",
    "#only rows of import\n",
    "all_positives = all_positives[['key', 'source', 'call_type', 'date', 'hour', 'frequency_1']].copy()\n",
    "all_positives.rename(columns = {'key':'filename'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34d5a299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T23:11:20.707365Z",
     "start_time": "2021-05-28T23:11:20.702216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6138 entries, 0 to 489\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   filename     6138 non-null   object \n",
      " 1   source       6138 non-null   object \n",
      " 2   call_type    6138 non-null   object \n",
      " 3   date         6138 non-null   object \n",
      " 4   hour         6138 non-null   float64\n",
      " 5   frequency_1  6138 non-null   float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 335.7+ KB\n"
     ]
    }
   ],
   "source": [
    "all_positives.info() #should only be ~6000, check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a320a9f5",
   "metadata": {},
   "source": [
    "#### Assign sample rate\n",
    "Sample rate is one of two frequencies; the rate for a dataset_id applies to all .wav files within that deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f7f9a76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T23:11:20.717333Z",
     "start_time": "2021-05-28T23:11:20.713605Z"
    }
   },
   "outputs": [],
   "source": [
    "srs = pd.read_csv('../data/sample_rates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bd78566",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T23:11:20.723523Z",
     "start_time": "2021-05-28T23:11:20.719208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>sample_rate_hz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>honolua2016</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kahekili1</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kahekili2</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>launiupoko2016</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lopa2016</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>makua2016</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>manele2016</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mauilanai2016</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mm17a</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mm17b</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nmala2016</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset_id  sample_rate_hz\n",
       "0      honolua2016           64000\n",
       "1        kahekili1           50000\n",
       "2        kahekili2           64000\n",
       "3   launiupoko2016           64000\n",
       "4         lopa2016           64000\n",
       "5        makua2016           50000\n",
       "6       manele2016           64000\n",
       "7    mauilanai2016           64000\n",
       "8            mm17a           50000\n",
       "9            mm17b           64000\n",
       "10       nmala2016           64000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b81eabf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T23:11:20.726783Z",
     "start_time": "2021-05-28T23:11:20.724848Z"
    }
   },
   "outputs": [],
   "source": [
    "sr_dict = {srs['dataset_id'][i] : srs['sample_rate_hz'][i] for i in range(len(srs))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41b536a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T23:11:20.731236Z",
     "start_time": "2021-05-28T23:11:20.728364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'honolua2016': 64000,\n",
       " 'kahekili1': 50000,\n",
       " 'kahekili2': 64000,\n",
       " 'launiupoko2016': 64000,\n",
       " 'lopa2016': 64000,\n",
       " 'makua2016': 50000,\n",
       " 'manele2016': 64000,\n",
       " 'mauilanai2016': 64000,\n",
       " 'mm17a': 50000,\n",
       " 'mm17b': 64000,\n",
       " 'nmala2016': 64000}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c9f011b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T23:11:20.737288Z",
     "start_time": "2021-05-28T23:11:20.732030Z"
    }
   },
   "outputs": [],
   "source": [
    "all_positives['sr_key'] = all_positives['filename'].map(lambda x: x.split('_')[0])\n",
    "all_positives['sample_rate'] = all_positives['sr_key'].map(sr_dict)\n",
    "all_positives.drop(columns='sr_key', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d350570a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T23:11:27.724155Z",
     "start_time": "2021-05-28T23:11:27.708766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6138, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>source</th>\n",
       "      <th>call_type</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>frequency_1</th>\n",
       "      <th>sample_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mm17b_00000333.e.wav</td>\n",
       "      <td>Dolphin</td>\n",
       "      <td>click</td>\n",
       "      <td>7/1/16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23896.5383</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mm17b_00000334.e.wav</td>\n",
       "      <td>Dolphin</td>\n",
       "      <td>click</td>\n",
       "      <td>7/1/16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21559.0068</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mm17b_00000335.e.wav</td>\n",
       "      <td>Dolphin</td>\n",
       "      <td>click</td>\n",
       "      <td>7/1/16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24621.9791</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mm17b_00000336.e.wav</td>\n",
       "      <td>Dolphin</td>\n",
       "      <td>click</td>\n",
       "      <td>7/1/16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27523.7424</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mm17b_00000337.e.wav</td>\n",
       "      <td>Dolphin</td>\n",
       "      <td>click</td>\n",
       "      <td>7/1/16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26516.1857</td>\n",
       "      <td>64000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename   source call_type    date  hour  frequency_1  \\\n",
       "0  mm17b_00000333.e.wav  Dolphin     click  7/1/16   3.0   23896.5383   \n",
       "1  mm17b_00000334.e.wav  Dolphin     click  7/1/16   3.0   21559.0068   \n",
       "2  mm17b_00000335.e.wav  Dolphin     click  7/1/16   3.0   24621.9791   \n",
       "3  mm17b_00000336.e.wav  Dolphin     click  7/1/16   4.0   27523.7424   \n",
       "4  mm17b_00000337.e.wav  Dolphin     click  7/1/16   4.0   26516.1857   \n",
       "\n",
       "   sample_rate  \n",
       "0        64000  \n",
       "1        64000  \n",
       "2        64000  \n",
       "3        64000  \n",
       "4        64000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_positives.shape)\n",
    "all_positives.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef258e",
   "metadata": {},
   "source": [
    "#### Break up by source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "946a089b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T23:11:41.223976Z",
     "start_time": "2021-05-28T23:11:41.217343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dolphin      6104\n",
       "Anthropog      25\n",
       "unknown         5\n",
       "Unknown         3\n",
       "Whale           1\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_positives.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "656f2621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T23:11:43.211469Z",
     "start_time": "2021-05-28T23:11:43.202767Z"
    }
   },
   "outputs": [],
   "source": [
    "anthro = all_positives.loc[all_positives['source'] == 'Anthropog'].copy()\n",
    "whale = all_positives.loc[all_positives['source'] == 'Whale'].copy()\n",
    "all_positives = all_positives.loc[all_positives['source'] == 'Dolphin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cb1414f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T23:11:43.934153Z",
     "start_time": "2021-05-28T23:11:43.895253Z"
    }
   },
   "outputs": [],
   "source": [
    "all_positives.to_csv('../data/dolphin_positives.csv', index=False)\n",
    "anthro.to_csv('../data/anthro_examples.csv', index=False)\n",
    "whale.to_csv('../data/whale_solo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6f471",
   "metadata": {},
   "source": [
    "## 2. Download loop: select and transfer data\n",
    "Currently I have an external hardrive of 190,000 audio files distributed among 11 folders, each representing a deployment of the recording device. Each folder contains positive and negative files intermingled. Only 6,104 of those files are positive, per the key above; which is a 96.7% majority for negative files. That's not a great ratio for training a model (at least one that will outperform baseline). To balance classes, I will randomly select negative files (from across all 11 sites) to achieve a 1:3 positive:negative ratio. Even if 1,000 of these positive files end up being set aside as a hold-out set, that still leaves me with a 1:4 ratio for training. There supposedly are more positive files en route, but I am unsure on their # or arrival time, so moving ahead as is.  \n",
    "\n",
    "---\n",
    "* 6,104 positive files @ 1p:3n ratio = 18,312 negative files\n",
    "* write fx to physically move all the positive files from external hardrive to scratch_data positive folder\n",
    "* once positive files removed, can freely random-sample from all sites for negatives\n",
    "* directories for each deployment about the same size: sample same # from each\n",
    "* projected total size = 90GB; ample room on laptop; means not having to rely on external connection for analysis\n",
    "    * Consider copying some example files as a small dummy-dataset for github. Github filesize limits mean can't push real data.\n",
    "    * scratch_data is included in .gitignore\n",
    "* Note: complete data backed up on separate drive. Can delete, rename, relocate with abandon.\n",
    "\n",
    "---\n",
    "code guidance: [1](https://stackoverflow.com/questions/8858008/how-to-move-a-file), [2](https://stackoverflow.com/questions/49280966/pulling-random-files-out-of-a-folder-for-sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "501ad499",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T01:48:37.973545Z",
     "start_time": "2021-05-29T01:48:37.968203Z"
    }
   },
   "outputs": [],
   "source": [
    "# relocate all positive dolphin id files from aggregated data to yes_dolphin folder\n",
    "\n",
    "def dolphins_assemble(file_list, origin, destination):\n",
    "    import shutil #os.rename might not move between devices\n",
    "    \n",
    "    directories = [i for i in os.listdir(origin) if '2016' in i] #all deployments titled with 2016\n",
    "    count = 0\n",
    "    \n",
    "    for i in directories:\n",
    "        \n",
    "        files = [f for f in os.listdir(f'{origin + i}/ewavs') if f.endswith('.wav')]\n",
    "        \n",
    "        for file in files:\n",
    "            if file in file_list:\n",
    "                shutil.move(f'{origin + i}/ewavs/{file}', destination+file)\n",
    "                count += 1\n",
    "                if count % 1000 == 0:\n",
    "                    print(count)\n",
    "            else:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "24aa60d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T01:55:10.249000Z",
     "start_time": "2021-05-29T01:48:45.430388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "origin = '/Volumes/hmm1mhm/'\n",
    "destination = '../scratch_data/yes_dolphin/'\n",
    "file_list = all_positives['filename'].to_list()\n",
    "\n",
    "dolphins_assemble(file_list, origin, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507726e9",
   "metadata": {},
   "source": [
    "Confirmed in file origin that positive id files are no longer in origin directories. As such, can random sample these directories for negative files. For this operation, copy the files as opposed to remove/rename. That way, negative training data can be resampled as desired. (Though also note that if resampling or adding new data, discard the old training copies or otherwise ensure there are no duplicates).\n",
    "* Target: 18,300 files\n",
    "* Deployments: 11, all similar file count (~16k)\n",
    "* Random Sample: 1664 from each  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "55dd7d3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T02:42:22.374218Z",
     "start_time": "2021-05-29T02:42:22.368555Z"
    }
   },
   "outputs": [],
   "source": [
    "# random sample (no replacement) negative files from aggregated to no_dolphin\n",
    "# equal samples from each site (directory)\n",
    "\n",
    "def sample_negatives(n_samples, origin, destination):\n",
    "    \n",
    "    import shutil #os.rename might not move between devices\n",
    "    \n",
    "    directories = [i for i in os.listdir(origin) if '2016' in i] #all deployments titled with 2016\n",
    "    count = 0\n",
    "    \n",
    "    for i in directories:\n",
    "        \n",
    "        files = [f for f in os.listdir(f'{origin + i}/ewavs') if f.endswith('.wav')]\n",
    "        \n",
    "        subsample = np.random.choice(files, size = n_samples, replace=False)\n",
    "        \n",
    "        for s in subsample:\n",
    "            shutil.copy(f'{origin + i}/ewavs/{s}', destination)\n",
    "            count += 1\n",
    "            if count % 3000 == 0:\n",
    "                print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cbbb4abd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T03:48:49.693359Z",
     "start_time": "2021-05-29T02:42:42.461033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n",
      "15000\n",
      "18000\n"
     ]
    }
   ],
   "source": [
    "origin = '/Volumes/hmm1mhm/'\n",
    "destination = '../scratch_data/no_dolphin/'\n",
    "\n",
    "sample_negatives(1664, origin, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51798db5",
   "metadata": {},
   "source": [
    "### Pau\n",
    "Pret.ty proud of this whole operation. Ready to start to start starting the actual project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
